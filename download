#!/usr/bin/env python3

import bs4
import requests
import os
import re
import shutil
import sys
import urllib
import util

"""
Downloads 1 year of DER SPIEGEL article PDFs
"""

def get_soup(url):
    r = requests.get(url)
    return bs4.BeautifulSoup(r.text, 'html.parser')

def resolve(url, relative_url):
    return urllib.parse.urljoin(url, relative_url)

def download(url, path):
    r = requests.get(url, stream=True)
    r.raw.decode_content = True
    with open(path + '.part', 'wb') as f:
        shutil.copyfileobj(r.raw, f)
    shutil.move(path + '.part', path)

try:
   _, year = sys.argv
except ValueError:
   print('Usage: download YEAR', file=sys.stderr)
   sys.exit(1)

year_url = 'http://www.spiegel.de/spiegel/print/index-{}.html'.format(year)
year_soup = get_soup(year_url)

for a in year_soup.find_all('a'):
    url = resolve(year_url, a.get('href'))
    match = re.match(
        r'https?://www.spiegel.de/spiegel/print/index-{}-(\d\d?)\.html'.format(year), url)
    if match:
        issue_url = url
        issue_number = match.group(1)
        issue_dir = os.path.join('articles', year, issue_number)
        util.makedirs(issue_dir)
        issue_soup = get_soup(issue_url)
        for a in issue_soup.find_all('a'):
            url = resolve(issue_url, a.get('href'))
            if re.match(r'https?://www.spiegel.de/spiegel/print/d-\d+\.html', url):
                article_url = url
                article_soup = get_soup(article_url)
                for a in article_soup.find_all('a'):
                    url = resolve(article_url, a.get('href'))
                    match = re.match(r'https?://magazin.spiegel.de/EpubDelivery/spiegel/pdf/(\d+)',
                                     url)
                    if match:
                        pdf_url = url
                        article_id = match.group(1)
                        pdf_file = os.path.join(issue_dir, '{}.pdf'.format(article_id))
                        if not os.path.isfile(pdf_file):
                            print(pdf_url)
                            download(pdf_url, pdf_file)
